{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2WgdbqVd6g5P"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pyaudio as p\n",
    "import librosa\n",
    "import logging\n",
    "import time\n",
    "import schedule\n",
    "import scipy.signal\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import six\n",
    "import subprocess\n",
    "import tensorflow.keras as keras\n",
    "from threading import Thread\n",
    "from array import array\n",
    "from datetime import timedelta as td\n",
    "from queue import Queue\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras import backend as K\n",
    "from gsmmodem.modem import GsmModem\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "lW0FDDr68wb8"
   },
   "outputs": [],
   "source": [
    "AUDIO_FORMAT = p.paFloat32\n",
    "AUDIO_RATE = 44100\n",
    "NUMBER_OF_AUDIO_CHANNELS = 1\n",
    "AUDIO_DEVICE_INDEX = [0] #Keep below 10\n",
    "NUMBER_OF_FRAMES_PER_BUFFER = 4410\n",
    "SAMPLE_DURATION = 2\n",
    "AUDIO_VOLUME_THRESHOLD = 0.2\n",
    "NOISE_REDUCTION_ENABLED = False\n",
    "MODEL_CONFIDENCE_THRESHOLD = 0.5\n",
    "MINIMUM_FREQUENCY = 20\n",
    "MAXIMUM_FREQUENCY = AUDIO_RATE // 2\n",
    "NUMBER_OF_MELS = 128\n",
    "NUMBER_OF_FFTS = NUMBER_OF_MELS * 20\n",
    "SMS_ALERTS_ENABLED = False\n",
    "ALERT_MESSAGE = \"ALERT: A Gunshot Was Detected on \"\n",
    "NETWORK_COVERAGE_TIMEOUT = 3600\n",
    "DESIGNATED_ALERT_RECIPIENTS = [\"9999999999\"]\n",
    "SCHEDULED_LOG_FILE_TRUNCATION_TIME = \"00:00\"\n",
    "sound_data = np.zeros(0, dtype = \"float32\")\n",
    "noise_sample_captured = False\n",
    "gunshot_sound_counter = 1\n",
    "noise_sample = []\n",
    "audio_analysis_queue = Queue()\n",
    "sms_alert_queue = Queue()\n",
    "path=os.getcwd()\n",
    "path=path+\"//\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "6dL0-z338uN4"
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger('debugger')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "ch = logging.FileHandler(path+'output.log',mode='w')\n",
    "ch.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "hdH1Zosh81cR"
   },
   "outputs": [],
   "source": [
    "labels = np.load(path+\"augmented_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kByOE4sM-B61",
    "outputId": "73aa7bff-a76e-48b9-e609-18989e395c56",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = np.array([(\"gun_shot\" if label == \"gun_shot\" else \"other\") for label in labels])\n",
    "label_binarizer = LabelBinarizer()\n",
    "labels = label_binarizer.fit_transform(labels)\n",
    "labels = np.hstack((labels, 1 - labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "-Iv9ncD8-DmY"
   },
   "outputs": [],
   "source": [
    "def _stft(y, n_fft, hop_length, win_length):\n",
    "    return librosa.stft(y = y, n_fft = n_fft, hop_length = hop_length, win_length = win_length)\n",
    "\n",
    "\n",
    "def _istft(y, hop_length, win_length):\n",
    "    return librosa.istft(y, hop_length, win_length)\n",
    "\n",
    "\n",
    "def _amp_to_db(x):\n",
    "    return librosa.core.logamplitude(x, ref_power = 1.0, amin = 1e-20, top_db = 80.0)  # Librosa 0.4.2 functionality\n",
    "\n",
    "\n",
    "def _db_to_amp(x):\n",
    "    return librosa.core.perceptual_weighting(x, frequencies = 1.0)  # Librosa 0.4.2 functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "s-qHjOfx-Hys"
   },
   "outputs": [],
   "source": [
    "def remove_noise(audio_clip,\n",
    "                noise_clip,\n",
    "                n_grad_freq = 2,\n",
    "                n_grad_time = 4,\n",
    "                n_fft = 2048,\n",
    "                win_length = 2048,\n",
    "                hop_length = 512,\n",
    "                n_std_thresh = 1.5,\n",
    "                prop_decrease = 1.0,\n",
    "                verbose = False):\n",
    "    \n",
    "    \"\"\" Removes noise from audio based upon a clip containing only noise\n",
    "\n",
    "    Args:\n",
    "        audio_clip (array): The first parameter.\n",
    "        noise_clip (array): The second parameter.\n",
    "        n_grad_freq (int): how many frequency channels to smooth over with the mask.\n",
    "        n_grad_time (int): how many time channels to smooth over with the mask.\n",
    "        n_fft (int): number audio of frames between STFT columns.\n",
    "        win_length (int): Each frame of audio is windowed by `window()`. The window will be of length `win_length` and then padded with zeros to match `n_fft`..\n",
    "        hop_length (int):number audio of frames between STFT columns.\n",
    "        n_std_thresh (int): how many standard deviations louder than the mean dB of the noise (at each frequency level) to be considered signal\n",
    "        prop_decrease (float): To what extent should you decrease noise (1 = all, 0 = none)\n",
    "        verbose: Whether to display time statistics for the noise reduction process\n",
    "\n",
    "    Returns:\n",
    "        array: The recovered signal with noise subtracted\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        start = time.time()\n",
    "        \n",
    "    # Takes a STFT over the noise sample\n",
    "    noise_stft = _stft(noise_clip, n_fft, hop_length, win_length)\n",
    "    noise_stft_db = _amp_to_db(np.abs(noise_stft))  # Converts the sample units to dB\n",
    "    \n",
    "    # Calculates statistics over the noise sample\n",
    "    mean_freq_noise = np.mean(noise_stft_db, axis = 1)\n",
    "    std_freq_noise = np.std(noise_stft_db, axis = 1)\n",
    "    noise_thresh = mean_freq_noise + std_freq_noise * n_std_thresh\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"STFT on noise:\", td(seconds = time.time() - start))\n",
    "        start = time.time()\n",
    "        \n",
    "    # Takes a STFT over the signal sample\n",
    "    sig_stft = _stft(audio_clip, n_fft, hop_length, win_length)\n",
    "    sig_stft_db = _amp_to_db(np.abs(sig_stft))\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"STFT on signal:\", td(seconds = time.time() - start))\n",
    "        start = time.time()\n",
    "        \n",
    "    # Calculates value to which to mask dB\n",
    "    mask_gain_dB = np.min(_amp_to_db(np.abs(sig_stft)))\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"Noise Threshold & Mask Gain in dB: \", noise_thresh, mask_gain_dB)\n",
    "    \n",
    "    # Creates a smoothing filter for the mask in time and frequency\n",
    "    smoothing_filter = np.outer(\n",
    "        np.concatenate(\n",
    "            [\n",
    "                np.linspace(0, 1, n_grad_freq + 1, endpoint = False),\n",
    "                np.linspace(1, 0, n_grad_freq + 2),\n",
    "            ]\n",
    "        )[1:-1],\n",
    "        np.concatenate(\n",
    "            [\n",
    "                np.linspace(0, 1, n_grad_time + 1, endpoint = False),\n",
    "                np.linspace(1, 0, n_grad_time + 2),\n",
    "            ]\n",
    "        )[1:-1]\n",
    "    )\n",
    "    \n",
    "    smoothing_filter = smoothing_filter / np.sum(smoothing_filter)\n",
    "    \n",
    "    # Calculates the threshold for each frequency/time bin\n",
    "    db_thresh = np.repeat(np.reshape(noise_thresh, [1, len(mean_freq_noise)]),\n",
    "                          np.shape(sig_stft_db)[1],\n",
    "                          axis = 0).T\n",
    "    \n",
    "    # Masks segment if the signal is above the threshold\n",
    "    sig_mask = sig_stft_db < db_thresh\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"Masking:\", td(seconds = time.time() - start))\n",
    "        start = time.time()\n",
    "        \n",
    "    # Convolves the mask with a smoothing filter\n",
    "    sig_mask = scipy.signal.fftconvolve(sig_mask, smoothing_filter, mode=\"same\")\n",
    "    sig_mask = sig_mask * prop_decrease\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"Mask convolution:\", td(seconds = time.time() - start))\n",
    "        start = time.time()\n",
    "        \n",
    "    # Masks the signal\n",
    "    sig_stft_db_masked = (sig_stft_db * (1 - sig_mask)\n",
    "                          + np.ones(np.shape(mask_gain_dB))\n",
    "                          * mask_gain_dB * sig_mask)  # Masks real\n",
    "    \n",
    "    sig_imag_masked = np.imag(sig_stft) * (1 - sig_mask)\n",
    "    sig_stft_amp = (_db_to_amp(sig_stft_db_masked) * np.sign(sig_stft)) + (1j * sig_imag_masked)\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"Mask application:\", td(seconds = time.time() - start))\n",
    "        start = time.time()\n",
    "        \n",
    "    # Recovers the signal\n",
    "    recovered_signal = _istft(sig_stft_amp, hop_length, win_length)\n",
    "    recovered_spec = _amp_to_db(\n",
    "        np.abs(_stft(recovered_signal, n_fft, hop_length, win_length))\n",
    "    )\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"Signal recovery:\", td(seconds = time.time() - start))\n",
    "        \n",
    "    # Returns noise-reduced audio sample\n",
    "    return recovered_signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "b-r1b0OX-PKC"
   },
   "outputs": [],
   "source": [
    "def power_to_db(S, ref=1.0, amin=1e-10, top_db=80.0):\n",
    "    S = np.asarray(S)\n",
    "    if amin <= 0:\n",
    "        logger.debug(\"ParameterError: amin must be strictly positive\")\n",
    "    if np.issubdtype(S.dtype, np.complexfloating):\n",
    "        logger.debug(\"Warning: power_to_db was called on complex input so phase information will be discarded.\")\n",
    "        magnitude = np.abs(S)\n",
    "    else:\n",
    "        magnitude = S\n",
    "    if six.callable(ref):\n",
    "        # User supplied a function to calculate reference power\n",
    "        ref_value = ref(magnitude)\n",
    "    else:\n",
    "        ref_value = np.abs(ref)\n",
    "    log_spec = 10.0 * np.log10(np.maximum(amin, magnitude))\n",
    "    log_spec -= 10.0 * np.log10(np.maximum(amin, ref_value))\n",
    "    if top_db is not None:\n",
    "        if top_db < 0:\n",
    "            logger.debug(\"ParameterError: top_db must be non-negative\")\n",
    "        log_spec = np.maximum(log_spec, log_spec.max() - top_db)\n",
    "    return log_spec\n",
    "\n",
    "\n",
    "def convert_audio_to_spectrogram(data):\n",
    "    spectrogram = librosa.feature.melspectrogram(y=data, sr=AUDIO_RATE,\n",
    "                                                 hop_length=HOP_LENGTH,\n",
    "                                                 fmin=MINIMUM_FREQUENCY,\n",
    "                                                 fmax=MAXIMUM_FREQUENCY,\n",
    "                                                 n_mels=NUMBER_OF_MELS,\n",
    "                                                 n_fft=NUMBER_OF_FFTS)\n",
    "    spectrogram = power_to_db(spectrogram)\n",
    "    spectrogram = spectrogram.astype(np.float32)\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "rn_lOMyP-VAx"
   },
   "outputs": [],
   "source": [
    "# Saves a two-second gunshot sample as a WAV file\n",
    "def create_gunshot_wav_file(microphone_data, index, timestamp):\n",
    "    import soundfile as sf\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S_%f\")[:-3]\n",
    "    timestamp_mod=str(timestamp)\n",
    "    f=\"A Gunshot is detected on: \"+ timestamp_mod  \n",
    "    device_info = pa.get_device_info_by_index(i)\n",
    "    #mock location\n",
    "    device_info['name'] =  \"CLO\"\n",
    "    device=device_info['name']\n",
    "    sf.write(path+'SystemSounds//'+device+timestamp+ \"_\"+str(index)+ \".wav\", microphone_data, 44100)\n",
    "    return f\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "-58YiXWT-ZFD"
   },
   "outputs": [],
   "source": [
    "def clear_log_file():\n",
    "    with open(path+\"output.log\", 'w'):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "m_3dvp6q-vh2"
   },
   "outputs": [],
   "source": [
    "# Loads 44100 x 1 Keras model from H5 file\n",
    "interpreter_1 = tf.lite.Interpreter(model_path = path+\"1D.tflite\")\n",
    "interpreter_1.allocate_tensors()\n",
    "    \n",
    "# Sets the input shape for the 44100 x 1 model\n",
    "input_details_1 = interpreter_1.get_input_details()\n",
    "output_details_1 = interpreter_1.get_output_details()\n",
    "input_shape_1 = input_details_1[0]['shape']\n",
    "\n",
    "# Loads 128 x 64 Keras model from H5 file\n",
    "interpreter_2 = tf.lite.Interpreter(model_path = path+\"128_x_64_2D.tflite\")\n",
    "interpreter_2.allocate_tensors()\n",
    "\n",
    "# Gets the input shape from the 128 x 64 Keras model\n",
    "input_details_2 = interpreter_2.get_input_details()\n",
    "output_details_2 = interpreter_2.get_output_details()\n",
    "input_shape_2 = input_details_2[0]['shape']\n",
    "\n",
    "# Loads 128 x 128 Keras model from H5 file\n",
    "interpreter_3 = tf.lite.Interpreter(model_path = path+\"128_x_128_2D.tflite\")\n",
    "interpreter_3.allocate_tensors()\n",
    "\n",
    "# Gets the input shape from the 128 x 128 Keras model\n",
    "input_details_3 = interpreter_3.get_input_details()\n",
    "output_details_3 = interpreter_3.get_output_details()\n",
    "input_shape_3 = input_details_3[0]['shape']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "eV-83ZqG_jUJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening from 0\n"
     ]
    }
   ],
   "source": [
    "#@title\n",
    "def callback(in_data, frame_count, time_info, status):\n",
    "    global sound_data\n",
    "    sound_buffer = np.frombuffer(in_data, dtype = \"float32\")\n",
    "    sound_data = np.append(sound_data, sound_buffer)\n",
    "    if len(sound_data) >= 88200:\n",
    "        audio_analysis_queue.put(sound_data)\n",
    "        current_time = time.ctime(time.time())\n",
    "        audio_analysis_queue.put(current_time)\n",
    "        sound_data = np.zeros(0, dtype = \"float32\")\n",
    "    return sound_buffer, p.paContinue\n",
    "\n",
    "pa = p.PyAudio()\n",
    "\n",
    "for i in AUDIO_DEVICE_INDEX:\n",
    "    stream = pa.open(format = AUDIO_FORMAT,\n",
    "                 rate = AUDIO_RATE,\n",
    "                 channels = NUMBER_OF_AUDIO_CHANNELS,\n",
    "                 input_device_index = i,\n",
    "                 frames_per_buffer = NUMBER_OF_FRAMES_PER_BUFFER,\n",
    "                 input = True,\n",
    "                 stream_callback = callback)\n",
    "    print('Listening from', i)\n",
    "# Starts the callback thread\n",
    "stream.start_stream()\n",
    "logger.debug(\"--- Listening to Audio Stream ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_input_device(audio):\n",
    "    pa= p.PyAudio()\n",
    "    for i in range(pa.get_device_count()-1):\n",
    "        device_info = pa.get_device_info_by_index(i)\n",
    "        device_info1=pa.get_device_info_by_index(i+1)\n",
    "        channels=max(device_info['maxInputChannels'],device_info1['maxInputChannels'])\n",
    "\n",
    "    for i in range(pa.get_device_count()-1):\n",
    "        device_info = pa.get_device_info_by_index(i)\n",
    "        if device_info['maxInputChannels']==channels:\n",
    "            #mock location\n",
    "            device_info['name'] =  \"CLO\" \n",
    "            device=device_info['name']\n",
    "    a=\"Device Location: \"+device\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "FQl4cbkJBYVK",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device Location: CLO A Gunshot is detected on: 2023_03_27_16_01_31_358\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m schedule\u001b[39m.\u001b[39mrun_pending()\n\u001b[0;32m      9\u001b[0m \u001b[39m# Gets a sample and its timestamp from the audio analysis queue\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m microphone_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(audio_analysis_queue\u001b[39m.\u001b[39;49mget(), dtype \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfloat32\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m time_of_sample_occurrence \u001b[39m=\u001b[39m audio_analysis_queue\u001b[39m.\u001b[39mget()\n\u001b[0;32m     13\u001b[0m \u001b[39m# Cleans up the global NumPy audio data source\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\swsmi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\queue.py:171\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_qsize():\n\u001b[1;32m--> 171\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait()\n\u001b[0;32m    172\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    173\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m\u001b[39m must be a non-negative number\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\swsmi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Starts the scheduler for clearing the primary log file\n",
    "schedule.every().day.at(SCHEDULED_LOG_FILE_TRUNCATION_TIME).do(clear_log_file)\n",
    "\n",
    "# This thread will run indefinitely\n",
    "while True:\n",
    "    # Refreshes the scheduler\n",
    "    schedule.run_pending()\n",
    "    \n",
    "    # Gets a sample and its timestamp from the audio analysis queue\n",
    "    microphone_data = np.array(audio_analysis_queue.get(), dtype = \"float32\")\n",
    "    time_of_sample_occurrence = audio_analysis_queue.get()\n",
    "    \n",
    "    # Cleans up the global NumPy audio data source\n",
    "    sound_data = np.zeros(0, dtype = \"float32\")\n",
    "        \n",
    "    # Finds the current sample's maximum frequency value\n",
    "    maximum_frequency_value = np.max(microphone_data)\n",
    "        \n",
    "    # Determines whether a given sample potentially contains a gunshot\n",
    "    if maximum_frequency_value >= AUDIO_VOLUME_THRESHOLD:\n",
    "        \n",
    "        # Displays the current sample's maximum frequency value\n",
    "        \n",
    "        \n",
    "        # Post-processes the microphone data\n",
    "        modified_microphone_data = librosa.resample(y = microphone_data, orig_sr = AUDIO_RATE, target_sr = 22050)\n",
    "        if NOISE_REDUCTION_ENABLED and noise_sample_captured:\n",
    "                # Acts as a substitute for normalization\n",
    "                modified_microphone_data = remove_noise(audio_clip = modified_microphone_data, noise_clip = noise_sample)\n",
    "                number_of_missing_hertz = 44100 - len(modified_microphone_data)\n",
    "                modified_microphone_data = np.array(modified_microphone_data.tolist() + [0 for i in range(number_of_missing_hertz)], dtype = \"float32\")\n",
    "        modified_microphone_data = modified_microphone_data[:44100]\n",
    "\n",
    "        # Passes an audio sample of an appropriate format into the model for inference\n",
    "        processed_data_1 = modified_microphone_data\n",
    "        processed_data_1 = processed_data_1.reshape(input_shape_1)\n",
    "\n",
    "        HOP_LENGTH = 345 * 2\n",
    "        processed_data_2 = convert_audio_to_spectrogram(data = modified_microphone_data)\n",
    "        processed_data_2 = processed_data_2.reshape(input_shape_2)\n",
    "            \n",
    "        HOP_LENGTH = 345\n",
    "        processed_data_3 = convert_audio_to_spectrogram(data = modified_microphone_data)\n",
    "        processed_data_3 = processed_data_3.reshape(input_shape_3)\n",
    "\n",
    "        # Performs inference with the instantiated TensorFlow Lite models\n",
    "        interpreter_1.set_tensor(input_details_1[0]['index'], processed_data_1)\n",
    "        interpreter_1.invoke()\n",
    "        probabilities_1 = interpreter_1.get_tensor(output_details_1[0]['index'])\n",
    "        \n",
    "        interpreter_2.set_tensor(input_details_2[0]['index'], processed_data_2)\n",
    "        interpreter_2.invoke()\n",
    "        probabilities_2 = interpreter_2.get_tensor(output_details_2[0]['index'])\n",
    "        \n",
    "        interpreter_3.set_tensor(input_details_3[0]['index'], processed_data_3)\n",
    "        interpreter_3.invoke()\n",
    "        probabilities_3 = interpreter_3.get_tensor(output_details_3[0]['index'])\n",
    "        \n",
    "        \n",
    "        #if label_binarizer.inverse_transform(probabilities_1[:, 0])[0]=='gun_shot':\n",
    "            #logger.debug()\n",
    "            \n",
    "            #logger.debug(\"The 128 x 64 model-predicted probability values: \" + str(probabilities_2[0]))\n",
    "            #logger.debug(\"The 128 x 128 model-predicted probability values: \" + str(probabilities_3[0]))\n",
    "            #logger.debug(\"The 44100 x 1 model-predicted sample class: \" + label_binarizer.inverse_transform(probabilities_1[:, 0])[0])\n",
    "            #logger.debug(\"The 128 x 64 model-predicted sample class: \" + label_binarizer.inverse_transform(probabilities_2[:, 0])[0])\n",
    "            #logger.debug(\"The 128 x 128 model-predicted sample class: \" + label_binarizer.inverse_transform(probabilities_3[:, 0])[0])\n",
    "        \n",
    "        # Records which models, if any, identified a gunshot\n",
    "        model_1_activated = probabilities_1[0][1] >= MODEL_CONFIDENCE_THRESHOLD\n",
    "        model_2_activated = probabilities_2[0][1] >= MODEL_CONFIDENCE_THRESHOLD\n",
    "        model_3_activated = probabilities_3[0][1] >= MODEL_CONFIDENCE_THRESHOLD\n",
    "\n",
    "        # Majority Rules: Determines if a gunshot sound was detected by a majority of the models\n",
    "        \n",
    "        #create_input_wav_file(modified_microphone_data, gunshot_sound_counter, time_of_sample_occurrence)\n",
    "        if model_1_activated :\n",
    "            output1=find_input_device(modified_microphone_data)\n",
    "            output2=create_gunshot_wav_file(modified_microphone_data, gunshot_sound_counter, time_of_sample_occurrence)\n",
    "            output = str(output1) +\" \"+ str(output2) \n",
    "            print(output)\n",
    "            with open(\"index.html\", \"r+\") as file:\n",
    "                file_data = file.read()\n",
    "                file.seek(0,0)\n",
    "                file.write(output + \"\\n\" + file_data)\n",
    "            \n",
    "            subprocess.call(r\"C:\\\\Users\\\\swsmi\\\\OneDrive\\\\Documents\\\\Gunshot-Detection\\\\GunshotDetection-main\\\\GunshotDetection-main\\\\commit.bat\")\n",
    "            \n",
    "\n",
    "            # Increments the counter for gunshot sound file names\n",
    "            gunshot_sound_counter += 1\n",
    "    \n",
    "    # Allows us to capture two seconds of background noise from the microphone for noise reduction\n",
    "    elif NOISE_REDUCTION_ENABLED and not noise_sample_captured:\n",
    "        noise_sample = librosa.resample(y = microphone_data, orig_sr = AUDIO_RATE, target_sr = 22050)\n",
    "        noise_sample = noise_sample[:44100]\n",
    "        noise_sample_captured = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"copy.txt\", \"w\") as file:\n",
    "    file.write(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "de5724879203b97cec6832b0cfa7e423784b13198564e37fe68d41802f3a2fe8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
